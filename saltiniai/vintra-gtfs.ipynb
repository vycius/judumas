{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GTFS\n",
    "## Savivaldybės\n",
    "VINTRA viešai skelbia [GTFS failus](https://www.visimarsrutai.lt/gtfs/), kurie apima viešojo transporto stoteles, maršrutus, tvarkaraščius ir kitą pagal GTFS specifikaciją apibrėžtą informaciją. Toliau pateikiama šių failų analizė.\n",
    "\n",
    "```{admonition} VINTRA pateikti ne visų savivaldybių GTFS failai\n",
    ":class: warning\n",
    "VINTRA pateikti 57 iš 60 savivaldybių GTFS duomenų failai.\n",
    "\n",
    "Trūksta: Telšių rajono, Šakių rajono, Širvintų rajono savivaldybių GTFS failų.\n",
    "```\n",
    "\n",
    "### Teisinis teikimo pagrindas\n",
    "> 1.  Viešojo transporto kelionių duomenų kaupimo tvarkos aprašas (toliau – Aprašas) nustato viešojo transporto kelionių duomenų (toliau – duomenys) teikimo į Viešojo transporto kelionių duomenų informacinę sistemą (toliau – IS „Vintra“) tvarką, pagal kurią IS „Vintra“ duomenų teikėjai **privalo** teikti viešojo transporto kelionių duomenis.{cite}`sumin_vintra_duomenu_kaupimo_tvarka`\n",
    "\n",
    "\n",
    "Duomenis į IS „Vintra“ teikia{cite}`sumin_vintra_duomenu_kaupimo_tvarka`:\n",
    "1. Lietuvos automobilių kelių direkcija prie Susisiekimo ministerijos;\n",
    "2. Lietuvos transporto saugos administracija, valdanti ir organizuojanti keleivių vežimą tolimojo ir tarptautinio reguliariojo susisiekimo maršrutais;\n",
    "3. Savivaldybių institucijos arba jų įgaliotos įstaigos, valdančios ir organizuojančios keleivių vežimą vietinio (miesto ar priemiestinio) reguliariojo susisiekimo maršrutais;\n",
    "4. Oro ir jūrų uostus valdančios įmonės;\n",
    "5. Vežėjai, teikiantys keleivių vežimo viešuoju geležinkelių transportu paslaugas;\n",
    "6. Vežėjai, teikiantys keleivių vežimo viešuoju jūrų ir vidaus vandenų transportu paslaugas;\n",
    "7. Vežėjai, teikiantys keleivių vežimo reguliariojo susisiekimo kelių transporto maršrutais paslaugas ir turintys atitinkamą paslaugų teikimo licenciją arba leidimą.\n",
    "\n",
    "\n",
    "Savivaldybių institucijos arba jų įgaliotos įstaigos, valdančios ir organizuojančios keleivių vežimą vietinio (miesto ar priemiestinio) reguliariojo susisiekimo maršrutais, teikia šiuos duomenis{cite}`sumin_vintra_duomenu_kaupimo_tvarka`:\n",
    "1. autobusų stočių, stotelių ir kitų maršrutų punktų;\n",
    "2. maršruto trasos trajektorijos;\n",
    "3. maršruto;\n",
    "4. reiso;\n",
    "5. tvarkaraščio;\n",
    "6. transporto priemonių geografinės padėties;\n",
    "7. tarifų ir kainoraščių;\n",
    "8. vežėjų.\n",
    "\n",
    "\n",
    "### Privalomų failų nebuvimas\n",
    "Pagal [specifikaciją](https://gtfs.org/schedule/reference/#dataset-files) GTFS privalo sudaryti bent penki failai (`agency.txt`, `stops.txt`, `routes.txt`, `trips.txt`, `stop_times.txt`).\n",
    "\n",
    "Toliau žemėlapyje pateikiamos savivaldybės, kurios neturi bent vieno iš privalomų failų.\n",
    "\n",
    "```{admonition} Trūksta bent vieno pagal GTFS specifikaciją privalomo failo\n",
    ":class: warning\n",
    "\n",
    "Tarp VINTRA pateiktų GTFS, 10 savivaldybių trūksta bent vieno pagal GTFS specifikaciją privalomo failo.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "working_directory = f'{os.getcwd()}/../data/saltiniai/vintra/'\n",
    "gtfs_files_directory = os.path.join(working_directory, 'gtfs')\n",
    "netex_directory = os.path.join(working_directory, 'netex')\n",
    "\n",
    "mapbox_access_token = open(\"../.mapbox_token\").read()\n",
    "px.set_mapbox_access_token(mapbox_access_token)\n",
    "\n",
    "lithuania_center = {'lat': 55.169438, 'lon': 23.881275}\n",
    "\n",
    "municipalities_gtfs_file_mapping = pd.read_csv(os.path.join(working_directory, 'vintra-gtfs-file-mapping.csv'),\n",
    "                                               na_filter=False)\n",
    "vintra_netex_mapping = pd.read_csv(os.path.join(working_directory, 'vintra-netex-file-mapping.csv'), na_filter=False)\n",
    "\n",
    "with open('../data/geojson/municipalities.geojson', 'r') as municipalities_geojson_file:\n",
    "    municipalities_geojson = json.load(municipalities_geojson_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to update GTFS files\n",
    "# import requests\n",
    "#\n",
    "# vintra_gtfs_df = pd.read_csv(os.path.join(working_directory, 'vintra-gtfs-files.csv'))\n",
    "#\n",
    "# for _, row in vintra_gtfs_df.iterrows():\n",
    "#     file_name = row['File']\n",
    "#     if file_name.endswith('.zip'):\n",
    "#         url = f'https://www.visimarsrutai.lt/gtfs/{file_name}'\n",
    "#\n",
    "#         response = requests.get(url, stream=True)\n",
    "#\n",
    "#         with open(os.path.join(gtfs_files_directory, file_name), \"wb\") as handle:\n",
    "#             for data in response.iter_content(chunk_size=8192):\n",
    "#                 handle.write(data)\n",
    "#\n",
    "#\n",
    "# for _, row in vintra_netex_mapping.iterrows():\n",
    "#     file_name = row['Failas']\n",
    "#     if file_name.endswith('.zip'):\n",
    "#         url = f'https://www.visimarsrutai.lt/netex/{file_name}'\n",
    "#\n",
    "#         response = requests.get(url, stream=True)\n",
    "#\n",
    "#         with open(os.path.join(netex_directory, file_name), \"wb\") as handle:\n",
    "#             for data in response.iter_content(chunk_size=8192):\n",
    "#                 handle.write(data)\n",
    "# gtfs_file_stats_df = pd.DataFrame()\n",
    "#\n",
    "# for file in sorted(os.listdir(gtfs_files_directory)):\n",
    "#     if file.endswith('.zip'):\n",
    "#         filename, _, _ = file.partition('.zip')\n",
    "#\n",
    "#         p = subprocess.Popen([\n",
    "#             f'java -jar gtfs-validator-301.jar -i gtfs/{file} -o reports -v {filename}_report.json -e {filename}_system_errors.json -n -c lt'],\n",
    "#             cwd=working_directory, shell=True, stdout=subprocess.PIPE,\n",
    "#             stderr=subprocess.PIPE)\n",
    "#         out, err = p.communicate(timeout=60)\n",
    "#         errcode = p.returncode\n",
    "#\n",
    "#         _, _, gtfs_files_txt = out.decode(\"utf-8\").partition('seconds\\n')\n",
    "#         gtfs_files = gtfs_files_txt.splitlines()\n",
    "#\n",
    "#         gtfs_files_dict = {'failas': filename}\n",
    "#         for gtfs_file_rep in gtfs_files:\n",
    "#             gtfs_file, c = gtfs_file_rep.split('\\t')\n",
    "#             gtfs_files_dict[gtfs_file] = c if c != 'MISSING_FILE' else None\n",
    "#\n",
    "#         gtfs_file_stats_df = gtfs_file_stats_df.append(gtfs_files_dict, ignore_index=True, )\n",
    "#\n",
    "# gtfs_file_stats_df = gtfs_file_stats_df.reindex(\n",
    "#     columns=[\n",
    "#         'failas',\n",
    "#         'agency.txt',\n",
    "#         'calendar.txt',\n",
    "#         'calendar_dates.txt',\n",
    "#         'routes.txt',\n",
    "#         'shapes.txt',\n",
    "#         'stop_times.txt',\n",
    "#         'stops.txt',\n",
    "#         'trips.txt',\n",
    "#         'fare_attributes.txt',\n",
    "#         'fare_rules.txt',\n",
    "#         'attributions.txt',\n",
    "#         'feed_info.txt',\n",
    "#         'frequencies.txt',\n",
    "#         'levels.txt',\n",
    "#         'pathways.txt',\n",
    "#         'transfers.txt',\n",
    "#         'translations.txt'\n",
    "#     ]\n",
    "# ).set_index('failas')\n",
    "#\n",
    "# gtfs_file_stats_df[\n",
    "#     [\n",
    "#         'agency.txt',\n",
    "#         'calendar.txt',\n",
    "#         'calendar_dates.txt',\n",
    "#         'routes.txt',\n",
    "#         'shapes.txt',\n",
    "#         'stop_times.txt',\n",
    "#         'stops.txt',\n",
    "#         'trips.txt',\n",
    "#         'fare_attributes.txt',\n",
    "#         'fare_rules.txt',\n",
    "#     ]\n",
    "# ] = gtfs_file_stats_df[\n",
    "#     [\n",
    "#         'agency.txt',\n",
    "#         'calendar.txt',\n",
    "#         'calendar_dates.txt',\n",
    "#         'routes.txt',\n",
    "#         'shapes.txt',\n",
    "#         'stop_times.txt',\n",
    "#         'stops.txt',\n",
    "#         'trips.txt',\n",
    "#         'fare_attributes.txt',\n",
    "#         'fare_rules.txt',\n",
    "#     ]\n",
    "# ].fillna('❌')\n",
    "#\n",
    "# gtfs_file_stats_df.fillna('⚠️', inplace=True)\n",
    "# gtfs_file_stats_df.style.set_sticky(axis=\"index\")\n",
    "#\n",
    "# gtfs_file_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "reports_dir = f'{working_directory}/gtfs-reports/'\n",
    "\n",
    "gtfs_notices_df = pd.DataFrame()\n",
    "\n",
    "for file in sorted(os.listdir(reports_dir)):\n",
    "    if file.endswith('report.json'):\n",
    "        gtfs_filename, _, _ = file.partition('_report.json')\n",
    "\n",
    "        with open(os.path.join(reports_dir, file)) as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "            for notice in data['notices']:\n",
    "                gtfs_notice_df = pd.DataFrame(\n",
    "                    [[f'{gtfs_filename}.zip', notice['code'], notice['severity'], notice['totalNotices']]],\n",
    "                    columns=['Failas', 'Klaida', 'Sunkumas', 'Viso']\n",
    "                )\n",
    "                gtfs_notices_df = pd.concat([gtfs_notices_df, gtfs_notice_df])\n",
    "\n",
    "gtfs_notices_df['Viso'] = pd.to_numeric(gtfs_notices_df['Viso'], downcast='integer')\n",
    "\n",
    "gtfs_errors_df = gtfs_notices_df[gtfs_notices_df['Sunkumas'] == 'ERROR'].drop(columns=['Sunkumas'])\n",
    "\n",
    "gtfs_errors_df = gtfs_errors_df.pivot_table(index='Failas', columns='Klaida', values='Viso', aggfunc='sum',\n",
    "                                            margins=True, fill_value=0)\n",
    "\n",
    "gtfs_notices_missing_required_file = gtfs_notices_df[gtfs_notices_df['Klaida'] == 'missing_required_file']\n",
    "\n",
    "municipalities_with_some_missing_required_file = municipalities_gtfs_file_mapping.merge(\n",
    "    gtfs_notices_missing_required_file,\n",
    "    on='Failas',\n",
    "    how='left'\n",
    ")[['Savivaldybe', 'Failas', 'Klaida']]\n",
    "\n",
    "municipalities_with_some_missing_required_file = municipalities_with_some_missing_required_file.replace(\n",
    "    {'Klaida': {\n",
    "        'missing_required_file': 1,\n",
    "        np.nan: 0}\n",
    "    }\n",
    ")\n",
    "\n",
    "fig = px.choropleth(\n",
    "    municipalities_with_some_missing_required_file,\n",
    "    geojson=municipalities_geojson,\n",
    "    locations=\"Savivaldybe\",\n",
    "    featureidkey=\"properties.name\",\n",
    "    color='Klaida',\n",
    "    center=lithuania_center,\n",
    "    fitbounds='locations',\n",
    "    basemap_visible=False,\n",
    "    color_continuous_scale='rdylgn_r',\n",
    "    projection=\"mercator\",\n",
    "    title='Savivaldybės turinčios privalomus GTFS failus VINTRA (pažymėtos žaliai)',\n",
    ")\n",
    "fig.update_layout(margin={\"r\": 0, \"l\": 0, \"b\": 0, \"t\": 32})\n",
    "fig.update_coloraxes(showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Duomenų rinkinio failai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from zipfile import BadZipFile\n",
    "\n",
    "\n",
    "def has_non_empty_gtfs_file(file: str, gtfs_file: str) -> bool:\n",
    "    if not file:\n",
    "        return False\n",
    "    with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "        gtfs_zip_files = gtfs_zip.namelist()\n",
    "\n",
    "        if gtfs_file not in gtfs_zip_files:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            with gtfs_zip.open(gtfs_file) as zip_file:\n",
    "                return pd.read_csv(zip_file).shape[0] > 0\n",
    "        except BadZipFile:\n",
    "            return False\n",
    "\n",
    "\n",
    "gtfs_files_by_specification = [\n",
    "    'agency.txt',\n",
    "    'stops.txt',\n",
    "    'routes.txt',\n",
    "    'trips.txt',\n",
    "    'stop_times.txt',\n",
    "    'calendar.txt',\n",
    "    'calendar_dates.txt',\n",
    "    'shapes.txt',\n",
    "    'feed_info.txt',\n",
    "    'fare_rules.txt',\n",
    "    'fare_attributes.txt',\n",
    "    'frequencies.txt',\n",
    "    'transfers.txt',\n",
    "    'pathways.txt',\n",
    "    'levels.txt',\n",
    "    'translations.txt',\n",
    "    'attributions.txt',\n",
    "]\n",
    "\n",
    "municipalities_files_availability = municipalities_gtfs_file_mapping.copy()\n",
    "\n",
    "for gtfs_file_by_specification in gtfs_files_by_specification:\n",
    "    municipalities_files_availability[gtfs_file_by_specification] = municipalities_files_availability.apply(\n",
    "        lambda m: has_non_empty_gtfs_file(m['Failas'], gtfs_file_by_specification), axis=1).astype(int)\n",
    "\n",
    "melted_municipalities_files_availability = municipalities_files_availability.melt(\n",
    "    id_vars=['Savivaldybe'],\n",
    "    value_vars=gtfs_files_by_specification,\n",
    "    var_name='GTFS Failas',\n",
    "    value_name='has_file',\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "fig = px.choropleth(\n",
    "    melted_municipalities_files_availability,\n",
    "    geojson=municipalities_geojson,\n",
    "    locations=\"Savivaldybe\",\n",
    "    featureidkey=\"properties.name\",\n",
    "    color='has_file',\n",
    "    color_continuous_scale='rdylgn',\n",
    "    fitbounds='locations',\n",
    "    basemap_visible=False,\n",
    "    projection=\"mercator\",\n",
    "    facet_col='GTFS Failas',\n",
    "    facet_col_wrap=3,\n",
    "    facet_row_spacing=0,\n",
    "    facet_col_spacing=0,\n",
    "    title='VINTRA savivaldybių duomenų rinkinio failai (žalia spalva - failas prieinamas)',\n",
    "    height=2500,\n",
    ")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 32, \"l\": 0, \"b\": 0})\n",
    "fig.update_coloraxes(showscale=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Maršrutai be galiojančių reisų\n",
    "\n",
    "Kiekvienas maršrutas susideda ir vieno ar keleto reisų, kurie turi galiojimo laiką. Kai duomenys ilgą laiką natnaujinami reisai nustoja galioti, kol maršrutai lieka visiškai be jokių galiojančių reisų. Toliau pateikiama kokia procentinė maršrutų dalis nebeturi nė vieno galiojančio reiso.\n",
    "\n",
    "```{admonition} Nė vieno galiojančio maršruto\n",
    ":class: warning\n",
    "23 savivaldybės neturi nė vieno galiojančio maršruto. Tai reikia, kad duomenys šiose savivaldybėse nėra atnaujinami.\n",
    "```\n",
    "\n",
    "```{admonition} Maršrutai be galiojančių reisų\n",
    ":class: warning\n",
    "29 savivaldybėse visi maršrutai turi bent vieną galiojantį reisą. Tai reiškia, kad likusiose savivaldybėse duomenys galimai yra neatnaujinami.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import Optional\n",
    "\n",
    "municipalities_valid_routes_df = municipalities_gtfs_file_mapping.copy()\n",
    "\n",
    "\n",
    "def calculate_valid_routes(file: str) -> float:\n",
    "    if not file:\n",
    "        return 0\n",
    "    with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "        gtfs_zip_files = gtfs_zip.namelist()\n",
    "        if \"calendar.txt\" not in gtfs_zip_files or \"routes.txt\" not in gtfs_zip_files or \"trips.txt\" not in gtfs_zip_files:\n",
    "            return 0\n",
    "\n",
    "        routes_df = pd.read_csv(gtfs_zip.open(\"routes.txt\"))\n",
    "        calendar_df = pd.read_csv(gtfs_zip.open(\"calendar.txt\"), parse_dates=['start_date', 'end_date'])\n",
    "        trips_df = pd.read_csv(gtfs_zip.open(\"trips.txt\"))\n",
    "\n",
    "        merged_df = trips_df.merge(calendar_df, on='service_id')\n",
    "\n",
    "        total_routes = routes_df['route_id'].nunique()\n",
    "        if total_routes == 0:\n",
    "            return 0\n",
    "\n",
    "        valid_routes = merged_df[(merged_df['end_date'] >= '2022-04-08')]['route_id'].nunique()\n",
    "\n",
    "        return (valid_routes / total_routes) * 100\n",
    "\n",
    "\n",
    "def calculate_last_valid_trip_date_formatted(file: str) -> Optional[str]:\n",
    "    if not file:\n",
    "        return '-'\n",
    "    with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "        gtfs_zip_files = gtfs_zip.namelist()\n",
    "        if \"calendar.txt\" not in gtfs_zip_files:\n",
    "            return '-'\n",
    "\n",
    "        calendar_df = pd.read_csv(gtfs_zip.open(\"calendar.txt\"), parse_dates=['start_date', 'end_date'])\n",
    "        max_end_date = calendar_df['end_date'].max()\n",
    "\n",
    "        return str(max_end_date.date()) if max_end_date else '-'\n",
    "\n",
    "\n",
    "municipalities_valid_routes_df['Dalis, %'] = municipalities_valid_routes_df.apply(\n",
    "    lambda m: calculate_valid_routes(m['Failas']), axis=1)\n",
    "\n",
    "municipalities_valid_routes_df['Paskutinis galiojantis reisas'] = municipalities_valid_routes_df.apply(\n",
    "    lambda m: calculate_last_valid_trip_date_formatted(m['Failas']), axis=1)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    municipalities_valid_routes_df,\n",
    "    geojson=municipalities_geojson,\n",
    "    locations=\"Savivaldybe\",\n",
    "    featureidkey=\"properties.name\",\n",
    "    color='Dalis, %',\n",
    "    color_continuous_scale='rdylgn',\n",
    "    fitbounds='locations',\n",
    "    basemap_visible=False,\n",
    "    projection=\"mercator\",\n",
    "    title='VINTRA galiojančių maršrutų dalis savivaldybėse (žaliau geriau)',\n",
    "    hover_data=['Paskutinis galiojantis reisas']\n",
    ")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 32, \"l\": 0, \"b\": 0})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Experiment without px.choropleth\n",
    "# from plotly.graph_objs.choropleth import ColorBar\n",
    "# import plotly.graph_objects as go\n",
    "#\n",
    "# fig = go.Figure(\n",
    "#     data=go.Choropleth(\n",
    "#         geojson=municipalities_geojson,\n",
    "#         locations=municipalities_valid_routes_df[\"Savivaldybe\"],\n",
    "#         featureidkey=\"properties.name\",\n",
    "#         z=municipalities_valid_routes_df['Dalis, %'],\n",
    "#         colorscale='reds',\n",
    "#         colorbar=ColorBar(\n",
    "#             ticksuffix='%',\n",
    "#             showticksuffix='last',\n",
    "#         ),\n",
    "#     ),\n",
    "# )\n",
    "#\n",
    "# fig.update_layout(\n",
    "#     title_text='Maršrutų be galiojančių reisų dalis VINTRA sistemoje',\n",
    "#     geo=dict(\n",
    "#         showframe=False,\n",
    "#         showcoastlines=False,\n",
    "#         visible=False,\n",
    "#         projection_type='mercator',\n",
    "#         fitbounds='locations',\n",
    "#     ),\n",
    "#     legend=dict(\n",
    "#         orientation=\"h\",\n",
    "#         yanchor=\"bottom\",\n",
    "#         y=1.02,\n",
    "#         xanchor=\"right\",\n",
    "#         x=1\n",
    "#     ),\n",
    "#     margin={\"r\": 0, \"t\": 32, \"l\": 0, \"b\": 0}\n",
    "# )\n",
    "#\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GTFS patikrinimas\n",
    "### GTFS patikrinimo klaidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# def show_notices_table_by_severity(severity: str) -> pd.DataFrame:\n",
    "#     gtfs_errors_df = gtfs_notices_df[gtfs_notices_df['sunkumas'] == severity].drop(columns=['sunkumas'])\n",
    "#\n",
    "#     gtfs_errors_df = gtfs_errors_df.pivot_table(index='failas', columns='klaida', values='viso', aggfunc='sum',\n",
    "#                                                 margins=True, fill_value=0)\n",
    "#\n",
    "#     gtfs_errors_df.style.set_sticky(axis=\"index\")\n",
    "#     gtfs_errors_df = gtfs_errors_df.style.apply(lambda x: [\"background: orange\" if v > 0 else '' for v in x], axis=1)\n",
    "#\n",
    "#     return gtfs_errors_df\n",
    "#\n",
    "#\n",
    "# show_notices_table_by_severity('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### GTFS patikrinimo įspėjimai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# show_notices_table_by_severity('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Stotelės"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "all_stops = pd.DataFrame()\n",
    "for file in sorted(os.listdir(gtfs_files_directory)):\n",
    "    if file.endswith('.zip') and file != 'gtfs_all.zip':\n",
    "        filename, _, _ = file.partition('.zip')\n",
    "\n",
    "        with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "            if \"stops.txt\" not in gtfs_zip.namelist():\n",
    "                continue\n",
    "\n",
    "            stops_csv = gtfs_zip.open(\"stops.txt\")\n",
    "\n",
    "        stops_df = pd.read_csv(stops_csv)\n",
    "        stops_df['failas'] = filename\n",
    "        all_stops = pd.concat([all_stops, stops_df])\n",
    "\n",
    "mapbox_access_token = open(\"../.mapbox_token\").read()\n",
    "px.set_mapbox_access_token(mapbox_access_token)\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    data_frame=all_stops,\n",
    "    lat='stop_lat',\n",
    "    lon='stop_lon',\n",
    "    mapbox_style=\"light\",\n",
    "    zoom=6,\n",
    "    title='Stotelės',\n",
    "    hover_name='stop_name',\n",
    "    color='failas',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox_layers=[\n",
    "        {\n",
    "            \"sourceattribution\": '© <a href=\"https://judumas.vycius.lt\" target=\"_blank\">Karolis Vyčius</a> © <a href=\"https://www.visimarsrutai.lt/gtfs/\" target=\"_blank\">Visimarsrutai.lt</a>'\n",
    "        }\n",
    "    ])\n",
    "fig.update_layout(margin={\"r\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with ZipFile(os.path.join(gtfs_files_directory, 'google_transit.zip')) as gtfs_zip:\n",
    "    stops_csv = gtfs_zip.open(\"stops.txt\")\n",
    "\n",
    "    google_transit_vintra_stops_df = pd.read_csv(stops_csv)\n",
    "\n",
    "    fig = px.scatter_mapbox(\n",
    "        data_frame=google_transit_vintra_stops_df,\n",
    "        lat='stop_lat',\n",
    "        lon='stop_lon',\n",
    "        mapbox_style=\"light\",\n",
    "        zoom=6,\n",
    "        title='Google Maps stotelės iš Vintra',\n",
    "        hover_name='stop_name',\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_layers=[\n",
    "            {\n",
    "                \"sourceattribution\": '© <a href=\"https://judumas.vycius.lt\" target=\"_blank\">Karolis Vyčius</a> © <a href=\"https://www.visimarsrutai.lt/gtfs/\" target=\"_blank\">Visimarsrutai.lt</a>'\n",
    "            }\n",
    "        ])\n",
    "    fig.update_layout(margin={\"r\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tolimasis susisiekimas\n",
    "### Teisinis duomenų teikimo pagrindas\n",
    "\n",
    "> 8. Vežėjas įsipareigoja:\n",
    "> 8.9. teikti viešojo transporto kelionių duomenis, nurodytus Viešojo transporto kelionių duomenų kaupimo tvarkos aprašo 15 punkte, į Viešojo transporto kelionių duomenų informacinę sistemą (IS „Vintra“);{cite}`ltsa_vezeju_prievole_teikti`\n",
    "\n",
    "Lietuvos transporto saugos administracija teikia šiuos tolimojo ir tarptautinio reguliariojo susisiekimo autobusais maršrutų duomenis{cite}`sumin_vintra_duomenu_kaupimo_tvarka`:\n",
    "1. autobusų stočių, stotelių ir kitų maršrutų punktų;\n",
    "2. maršruto trasos trajektorijos;\n",
    "3. maršruto;\n",
    "4. reiso;\n",
    "5. tvarkaraščio;\n",
    "6. vežėjų;\n",
    "7. transporto priemonių geografinės padėties;\n",
    "8. tarifų ir kainoraščių.\n",
    "\n",
    "Vežėjai, teikiantys keleivių vežimo tolimojo ir tarptautinio reguliariojo susisiekimo maršrutais paslaugas, teikia šiuos duomenis{cite}`sumin_vintra_duomenu_kaupimo_tvarka`:\n",
    "15.1.  transporto priemonių geografinės padėties;\n",
    "15.2.  tarifų ir kainoraščių;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gtfs_notices_df[gtfs_notices_df['Failas'] == 'LTSAR.zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_invalid_routes_debug(file: str) -> float:\n",
    "    if not file:\n",
    "        return 100\n",
    "    with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "        gtfs_zip_files = gtfs_zip.namelist()\n",
    "        print('')\n",
    "        if \"calendar.txt\" not in gtfs_zip_files or \"routes.txt\" not in gtfs_zip_files or \"trips.txt\" not in gtfs_zip_files:\n",
    "            return 100\n",
    "\n",
    "        routes_df = pd.read_csv(gtfs_zip.open(\"routes.txt\"))\n",
    "        calendar_df = pd.read_csv(gtfs_zip.open(\"calendar.txt\"), parse_dates=['start_date', 'end_date'])\n",
    "        trips_df = pd.read_csv(gtfs_zip.open(\"trips.txt\"))\n",
    "\n",
    "        merged_df = trips_df.merge(calendar_df, on='service_id')\n",
    "\n",
    "        total_routes = routes_df['route_id'].nunique()\n",
    "        if total_routes == 0:\n",
    "            return 100\n",
    "\n",
    "        valid_routes = merged_df[(merged_df['end_date'] >= '2022-04-08')]['route_id'].nunique()\n",
    "\n",
    "        return (1 - valid_routes / total_routes) * 100\n",
    "\n",
    "\n",
    "with ZipFile(os.path.join(gtfs_files_directory, 'SiauliuM.zip')) as gtfs_zip:\n",
    "    df = pd.read_csv(gtfs_zip.open('calendar.txt'), parse_dates=['start_date', 'end_date'])\n",
    "\n",
    "    print(df.head().sort_values('end_date', ascending=False))\n",
    "\n",
    "# print(calculate_invalid_routes_debug('PanevezioM.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with ZipFile(os.path.join(gtfs_files_directory, 'LTSAR.zip')) as gtfs_zip:\n",
    "    ltsa_stops_df = pd.read_csv(gtfs_zip.open(\"stops.txt\"))\n",
    "\n",
    "    fig = px.scatter_mapbox(\n",
    "        data_frame=ltsa_stops_df,\n",
    "        lat='stop_lat',\n",
    "        lon='stop_lon',\n",
    "        mapbox_style=\"light\",\n",
    "        zoom=6,\n",
    "        title='LTSA',\n",
    "        hover_name='stop_name',\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_layers=[\n",
    "            {\n",
    "                \"sourceattribution\": '© <a href=\"https://judumas.vycius.lt\" target=\"_blank\">Karolis Vyčius</a> © <a href=\"https://www.visimarsrutai.lt/gtfs/\" target=\"_blank\">Visimarsrutai.lt</a>'\n",
    "            }\n",
    "        ])\n",
    "    fig.update_layout(margin={\"r\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
