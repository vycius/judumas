{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# VINTRA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from itables import init_notebook_mode\n",
    "import os\n",
    "import subprocess\n",
    "from zipfile import ZipFile\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "working_directory = f'{os.getcwd()}/../data/gtfs/vintra/'\n",
    "gtfs_files_directory = f'{working_directory}/gtfs-files/'\n",
    "#\n",
    "# vintra_gtfs_df = pd.read_csv(os.path.join(working_directory, 'vintra-gtfs-files.csv'))\n",
    "#\n",
    "# for _, row in vintra_gtfs_df.iterrows():\n",
    "#     file_name = row['File']\n",
    "#     if file_name.endswith('.zip'):\n",
    "#         url = f'https://www.visimarsrutai.lt/gtfs/{file_name}'\n",
    "#\n",
    "#         response = requests.get(url, stream=True)\n",
    "#\n",
    "#         with open(os.path.join(gtfs_files_directory, file_name), \"wb\") as handle:\n",
    "#             for data in response.iter_content(chunk_size=8192):\n",
    "#                 handle.write(data)\n",
    "\n",
    "mapbox_access_token = open(\"../.mapbox_token\").read()\n",
    "px.set_mapbox_access_token(mapbox_access_token)\n",
    "\n",
    "lithuania_center = {'lat': 55.169438, 'lon': 23.881275}\n",
    "\n",
    "with open('../data/geojson/municipalities.geojson', 'r') as municipalities_geojson_file:\n",
    "    municipalities_geojson = json.load(municipalities_geojson_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "municipalities_valid_routes_df = pd.read_csv(os.path.join(working_directory, 'vintra-file-mapping.csv'))\n",
    "\n",
    "\n",
    "def calculate_invalid_routes(file: str) -> float:\n",
    "    with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "        gtfs_zip_files = gtfs_zip.namelist()\n",
    "        if \"calendar.txt\" not in gtfs_zip_files or \"routes.txt\" not in gtfs_zip_files or \"trips.txt\" not in gtfs_zip_files:\n",
    "            return 100\n",
    "\n",
    "        routes_df = pd.read_csv(gtfs_zip.open(\"routes.txt\"))\n",
    "        calendar_df = pd.read_csv(gtfs_zip.open(\"calendar.txt\"), parse_dates=['start_date', 'end_date'])\n",
    "        trips_df = pd.read_csv(gtfs_zip.open(\"trips.txt\"))\n",
    "\n",
    "        merged_df = trips_df.merge(calendar_df, on='service_id')\n",
    "\n",
    "        total_routes = routes_df['route_id'].nunique()\n",
    "        valid_routes = merged_df[(merged_df['start_date'] <= '2022-04-08') & (merged_df['end_date'] >= '2022-04-08')]['route_id'].nunique()\n",
    "\n",
    "        return (1 - valid_routes / total_routes) * 100\n",
    "\n",
    "\n",
    "municipalities_valid_routes_df['Negaliojančių maršrutų dalis'] = municipalities_valid_routes_df.apply(lambda m: calculate_invalid_routes(m['Failas']), axis=1)\n",
    "\n",
    "\n",
    "fig = px.choropleth_mapbox(\n",
    "    municipalities_valid_routes_df,\n",
    "    geojson=municipalities_geojson,\n",
    "    locations=\"Savivaldybe\",\n",
    "    featureidkey=\"properties.name\",\n",
    "    color='Negaliojančių maršrutų dalis',\n",
    "    center=lithuania_center,\n",
    "    mapbox_style=\"light\",\n",
    "    color_continuous_scale='reds',\n",
    "    zoom=6,\n",
    "    title='Negaliojančių maršrutų dalis VINTRA sistemoje',\n",
    ")\n",
    "fig.update_layout(margin={\"r\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gtfs_file_stats_df = pd.DataFrame()\n",
    "\n",
    "for file in sorted(os.listdir(gtfs_files_directory)):\n",
    "    if file.endswith('.zip'):\n",
    "        filename, _, _ = file.partition('.zip')\n",
    "\n",
    "        p = subprocess.Popen([\n",
    "            f'java -jar gtfs-validator-301.jar -i gtfs-files/{file} -o reports -v {filename}_report.json -e {filename}_system_errors.json -n -c lt'],\n",
    "            cwd=working_directory, shell=True, stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE)\n",
    "        out, err = p.communicate(timeout=60)\n",
    "        errcode = p.returncode\n",
    "\n",
    "        _, _, gtfs_files_txt = out.decode(\"utf-8\").partition('seconds\\n')\n",
    "        gtfs_files = gtfs_files_txt.splitlines()\n",
    "\n",
    "        gtfs_files_dict = {'failas': filename}\n",
    "        for gtfs_file_rep in gtfs_files:\n",
    "            gtfs_file, c = gtfs_file_rep.split('\\t')\n",
    "            gtfs_files_dict[gtfs_file] = c if c != 'MISSING_FILE' else None\n",
    "\n",
    "        gtfs_file_stats_df = gtfs_file_stats_df.append(gtfs_files_dict, ignore_index=True, )\n",
    "\n",
    "gtfs_file_stats_df = gtfs_file_stats_df.reindex(\n",
    "    columns=[\n",
    "        'failas',\n",
    "        'agency.txt',\n",
    "        'calendar.txt',\n",
    "        'calendar_dates.txt',\n",
    "        'routes.txt',\n",
    "        'shapes.txt',\n",
    "        'stop_times.txt',\n",
    "        'stops.txt',\n",
    "        'trips.txt',\n",
    "        'fare_attributes.txt',\n",
    "        'fare_rules.txt',\n",
    "        'attributions.txt',\n",
    "        'feed_info.txt',\n",
    "        'frequencies.txt',\n",
    "        'levels.txt',\n",
    "        'pathways.txt',\n",
    "        'transfers.txt',\n",
    "        'translations.txt'\n",
    "    ]\n",
    ").set_index('failas')\n",
    "\n",
    "\n",
    "gtfs_file_stats_df[\n",
    "    [\n",
    "        'agency.txt',\n",
    "        'calendar.txt',\n",
    "        'calendar_dates.txt',\n",
    "        'routes.txt',\n",
    "        'shapes.txt',\n",
    "        'stop_times.txt',\n",
    "        'stops.txt',\n",
    "        'trips.txt',\n",
    "        'fare_attributes.txt',\n",
    "        'fare_rules.txt',\n",
    "    ]\n",
    "] = gtfs_file_stats_df[\n",
    "    [\n",
    "        'agency.txt',\n",
    "        'calendar.txt',\n",
    "        'calendar_dates.txt',\n",
    "        'routes.txt',\n",
    "        'shapes.txt',\n",
    "        'stop_times.txt',\n",
    "        'stops.txt',\n",
    "        'trips.txt',\n",
    "        'fare_attributes.txt',\n",
    "        'fare_rules.txt',\n",
    "    ]\n",
    "].fillna('❌')\n",
    "\n",
    "gtfs_file_stats_df.fillna('⚠️', inplace=True)\n",
    "gtfs_file_stats_df.style.set_sticky(axis=\"index\")\n",
    "\n",
    "gtfs_file_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "reports_dir = f'{working_directory}/reports/'\n",
    "\n",
    "gtfs_notices_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for file in sorted(os.listdir(reports_dir)):\n",
    "    if file.endswith('report.json'):\n",
    "        gtfs_filename, _, _ = file.partition('_report.json')\n",
    "\n",
    "        with open(os.path.join(reports_dir, file)) as fp:\n",
    "                data = json.load(fp)\n",
    "\n",
    "                for notice in data['notices']:\n",
    "                    gtfs_notices_df = gtfs_notices_df.append({\n",
    "                        'failas': gtfs_filename,\n",
    "                        'klaida': notice['code'],\n",
    "                        'sunkumas': notice['severity'],\n",
    "                        'viso': notice['totalNotices'],\n",
    "                    }, ignore_index=True, )\n",
    "\n",
    "\n",
    "gtfs_notices_df['viso'] = pd.to_numeric(gtfs_notices_df['viso'], downcast='integer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GTFS patikrinimas\n",
    "### GTFS patikrinimo klaidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def show_notices_table_by_severity(severity: str) -> pd.DataFrame:\n",
    "    gtfs_errors_df = gtfs_notices_df[gtfs_notices_df['sunkumas'] == severity].drop(columns=['sunkumas'])\n",
    "\n",
    "    gtfs_errors_df = gtfs_errors_df.pivot_table(index='failas', columns='klaida', values='viso', aggfunc='sum', margins=True, fill_value=0)\n",
    "\n",
    "\n",
    "    gtfs_errors_df.style.set_sticky(axis=\"index\")\n",
    "    gtfs_errors_df = gtfs_errors_df.style.apply(lambda x: [\"background: orange\" if v >0 else '' for v in x], axis = 1)\n",
    "\n",
    "    return gtfs_errors_df\n",
    "\n",
    "show_notices_table_by_severity('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTFS patikrinimo įspėjimai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "show_notices_table_by_severity('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stotelės"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gtfs_functions as gtfs\n",
    "import plotly.express as px\n",
    "\n",
    "all_stops = pd.DataFrame()\n",
    "for file in sorted(os.listdir(gtfs_files_directory)):\n",
    "    if file.endswith('.zip') and file != 'gtfs_all.zip':\n",
    "        filename, _, _ = file.partition('.zip')\n",
    "\n",
    "        with ZipFile(os.path.join(gtfs_files_directory, file)) as gtfs_zip:\n",
    "            if \"stops.txt\" not in gtfs_zip.namelist():\n",
    "                continue\n",
    "\n",
    "            stops_csv = gtfs_zip.open(\"stops.txt\")\n",
    "\n",
    "        stops_df = pd.read_csv(stops_csv)\n",
    "        stops_df['failas'] = filename\n",
    "        all_stops = pd.concat([all_stops, stops_df])\n",
    "\n",
    "mapbox_access_token = open(\"../.mapbox_token\").read()\n",
    "px.set_mapbox_access_token(mapbox_access_token)\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    data_frame=all_stops,\n",
    "    lat='stop_lat',\n",
    "    lon='stop_lon',\n",
    "    mapbox_style=\"light\",\n",
    "    zoom=6,\n",
    "    title='Stotelės',\n",
    "    hover_name='stop_name',\n",
    "    color='failas',\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    mapbox_layers=[\n",
    "        {\n",
    "            \"sourceattribution\": '© <a href=\"https://judumas.vycius.lt\" target=\"_blank\">Karolis Vyčius</a> © <a href=\"https://www.visimarsrutai.lt/gtfs/\" target=\"_blank\">Visimarsrutai.lt</a>'\n",
    "        }\n",
    "    ])\n",
    "fig.update_layout(margin={\"r\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with ZipFile(os.path.join(gtfs_files_directory, 'google_transit.zip')) as gtfs_zip:\n",
    "    stops_csv = gtfs_zip.open(\"stops.txt\")\n",
    "\n",
    "    google_transit_vintra_stops_df = pd.read_csv(stops_csv)\n",
    "\n",
    "    fig = px.scatter_mapbox(\n",
    "        data_frame=google_transit_vintra_stops_df,\n",
    "        lat='stop_lat',\n",
    "        lon='stop_lon',\n",
    "        mapbox_style=\"light\",\n",
    "        zoom=6,\n",
    "        title='Google Maps stotelės iš Vintra',\n",
    "        hover_name='stop_name',\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_layers=[\n",
    "            {\n",
    "                \"sourceattribution\": '© <a href=\"https://judumas.vycius.lt\" target=\"_blank\">Karolis Vyčius</a> © <a href=\"https://www.visimarsrutai.lt/gtfs/\" target=\"_blank\">Visimarsrutai.lt</a>'\n",
    "            }\n",
    "        ])\n",
    "    fig.update_layout(margin={\"r\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
